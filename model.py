import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import os
import joblib
import plotly.express as px
import streamlit as st
import datetime

from statsmodels.tsa.arima.model import ARIMA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

def render_colored_card(title, value, subtitle, color1, color2, radius="2.2rem", icon=""):
    return f"""
    <div style="
        border-radius: {radius};
        background: linear-gradient(135deg, {color1} 0%, {color2} 100%);
        box-shadow: 0 4px 32px 0 rgba(50,50,93,.08), 0 1.5px 2.5px 0 rgba(0,0,0,.07);
        padding: 2rem 1.5rem 1.5rem 1.5rem;
        margin-bottom: 1.8rem;
        text-align:center;
        position:relative;
    ">
        <div style='font-size:2.1rem; font-weight:800; color:#fff; letter-spacing:1.5px; margin-bottom:0.5rem;'>{icon} {title}</div>
        <div style='font-size:2.2rem; font-weight:700; color:#222; margin-bottom:0.7rem;'>{value}</div>
        <div style='font-size:1.1rem; color:#fff; letter-spacing:1.1px'>{subtitle}</div>
    </div>
    """

MODEL_DIR = "model_artifacts"
PREDICTIONS_DIR = "predictions"
for directory in [MODEL_DIR, PREDICTIONS_DIR]:
    if not os.path.exists(directory):
        os.makedirs(directory)

def load_and_preprocess_data(file_path):
    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
        return None

    if df.shape[1] > 8:
        cols_to_drop = list(range(8, df.shape[1]))
        df = df.drop(df.columns[cols_to_drop], axis=1)
    df = df.dropna(subset=['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©'])
    for col in ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']:
        df[col] = df[col].astype(str).str.strip()
    unknown_indices = df[df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] == 'Unknown'].index
    n_unknown = len(unknown_indices)
    regions = [1.0, 2.0]
    assigned_regions = np.tile(regions, int(np.ceil(n_unknown / len(regions))))[:n_unknown]
    np.random.shuffle(assigned_regions)
    df.loc[unknown_indices, 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] = assigned_regions
    return df

def prepare_and_train_models(df):
    Q1 = df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.25)
    Q3 = df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_clean = df[(df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'] >= lower_bound) & (df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'] <= upper_bound)].copy()

    df_clean['Ø§Ù„Ø±Ø¨Ø¹'] = ((df_clean['Ø§Ù„Ø´Ù‡Ø±'] - 1) // 3 + 1).astype(int)
    df_clean['Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ'] = df_clean['Ø§Ù„Ø´Ù‡Ø±'].apply(lambda x: 1 if x in [6, 7, 8, 9] else 0)
    df_clean['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].transform('count')
    df_clean['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'].transform('count')
    top_clients = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].value_counts().nlargest(10).index
    df_clean['Ø§Ù„Ø¹Ù…ÙŠÙ„_Top'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].apply(lambda x: x if x in top_clients else 'Other')
    df_clean = df_clean.sort_values(['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±'])
    df_clean['ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].shift(1)
    df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = np.log1p(df_clean['ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'])
    df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].fillna(df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].mean())

    label_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©', 'Ø§Ù„Ø¹Ù…ÙŠÙ„_Top']
    label_encoders = {}
    for col in label_cols:
        df_clean[col] = df_clean[col].astype(str).str.strip()
        le = LabelEncoder()
        df_clean[col] = le.fit_transform(df_clean[col])
        label_encoders[col] = le
        joblib.dump(le, os.path.join(MODEL_DIR, f"{col}_encoder.pkl"))

    numeric_cols = ['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ù„Ø±Ø¨Ø¹', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬', 'log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©']
    scaler = StandardScaler()
    df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])
    joblib.dump(scaler, os.path.join(MODEL_DIR, "scaler.pkl"))

    feature_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©', 'Ø§Ù„Ø¹Ù…ÙŠÙ„_Top', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±',
                    'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ù„Ø±Ø¨Ø¹', 'Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬', 'log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©']

    X = df_clean[feature_cols]
    y = df_clean['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model_xgb = XGBRegressor(n_estimators=150, max_depth=5, learning_rate=0.05, random_state=42, reg_alpha=1.0, reg_lambda=1.0)
    model_xgb.fit(X_train, y_train)
    joblib.dump(model_xgb, os.path.join(MODEL_DIR, "xgboost_model.pkl"))
    y_pred = model_xgb.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred) ** 0.5
    r2 = r2_score(y_test, y_pred)

    arima_series = df.groupby(['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±'])['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().reset_index()
    arima_series['ds'] = pd.to_datetime(dict(year=arima_series['Ø§Ù„Ø³Ù†Ø©'], month=arima_series['Ø§Ù„Ø´Ù‡Ø±'], day=1))
    arima_series = arima_series.set_index('ds')
    arima_y = arima_series['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±']
    arima_order = (1, 1, 1)
    arima_model = ARIMA(arima_y, order=arima_order)
    arima_result = arima_model.fit()
    joblib.dump(arima_result, os.path.join(MODEL_DIR, "arima_model.pkl"))

    X_ann = X.values
    y_ann = y.values
    ann_model = Sequential([
        Dense(64, activation='relu', input_shape=(X_ann.shape[1],)),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    ann_model.compile(optimizer='adam', loss='mse')
    ann_model.fit(X_ann, y_ann, epochs=40, batch_size=16, verbose=0, callbacks=[EarlyStopping(patience=5)])
    ann_model.save(os.path.join(MODEL_DIR, "ann_model.h5"))

    return {
        "xgboost": (model_xgb, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean, rmse, r2),
        "arima": (arima_result, arima_y),
        "ann": (ann_model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean)
    }

def retrieve_or_predict(row, orig_df, model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean):
    row = row.copy()
    for col in ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']:
        row[col] = str(row[col]).strip()
    row['Ø§Ù„Ø³Ù†Ø©'] = int(row['Ø§Ù„Ø³Ù†Ø©'])
    row['Ø§Ù„Ø´Ù‡Ø±'] = int(row['Ø§Ù„Ø´Ù‡Ø±'])
    row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'] = int(row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'])
    lookup_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']
    matched = orig_df
    for col in lookup_cols:
        matched = matched[matched[col] == row[col]]
    if not matched.empty:
        return float(matched.iloc[0]['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±']), "Ø§Ø³ØªØ±Ø¬Ø§Ø¹"
    tmp = row.copy()
    tmp['Ø§Ù„Ø±Ø¨Ø¹'] = ((tmp['Ø§Ù„Ø´Ù‡Ø±'] - 1) // 3 + 1)
    tmp['Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ'] = 1 if tmp['Ø§Ù„Ø´Ù‡Ø±'] in [6, 7, 8, 9] else 0
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'], 1)
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'], 1)
    tmp['Ø§Ù„Ø¹Ù…ÙŠÙ„_Top'] = tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] if tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] in top_clients else 'Other'
    tmp['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].mean()
    for col in label_encoders:
        le = label_encoders[col]
        if tmp[col] not in le.classes_ and 'Other' in le.classes_:
            tmp[col] = 'Other'
        elif tmp[col] not in le.classes_:
            tmp[col] = le.classes_[0]
        tmp[col] = le.transform([str(tmp[col])])[0]
    for col in numeric_cols:
        tmp[col] = float(tmp[col])
    tmp_arr = np.array([tmp[col] for col in numeric_cols]).reshape(1, -1)
    tmp_scaled = scaler.transform(tmp_arr)[0]
    for i, col in enumerate(numeric_cols):
        tmp[col] = tmp_scaled[i]
    tmp_X = pd.DataFrame([tmp])[feature_cols]
    return float(model.predict(tmp_X)[0]), "ØªÙˆÙ‚Ø¹"

def predict_arima(row, arima_model, arima_y):
    target_date = pd.Timestamp(year=int(row['Ø§Ù„Ø³Ù†Ø©']), month=int(row['Ø§Ù„Ø´Ù‡Ø±']), day=1)
    last_date = arima_y.index[-1]
    n_periods = (target_date.year - last_date.year) * 12 + (target_date.month - last_date.month)
    if n_periods <= 0:
        try:
            return float(arima_y.loc[target_date]), "Ø§Ø³ØªØ±Ø¬Ø§Ø¹"
        except:
            return float(arima_y.mean()), "ØªÙˆÙ‚Ø¹ Ù…ØªÙˆØ³Ø·"
    pred = arima_model.forecast(steps=n_periods)
    return float(pred.values[-1]), "ØªÙˆÙ‚Ø¹"

def predict_ann(row, model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean):
    row = row.copy()
    for col in ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']:
        row[col] = str(row[col]).strip()
    row['Ø§Ù„Ø³Ù†Ø©'] = int(row['Ø§Ù„Ø³Ù†Ø©'])
    row['Ø§Ù„Ø´Ù‡Ø±'] = int(row['Ø§Ù„Ø´Ù‡Ø±'])
    row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'] = int(row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'])
    tmp = row.copy()
    tmp['Ø§Ù„Ø±Ø¨Ø¹'] = ((tmp['Ø§Ù„Ø´Ù‡Ø±'] - 1) // 3 + 1)
    tmp['Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ'] = 1 if tmp['Ø§Ù„Ø´Ù‡Ø±'] in [6, 7, 8, 9] else 0
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'], 1)
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'], 1)
    tmp['Ø§Ù„Ø¹Ù…ÙŠÙ„_Top'] = tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] if tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] in top_clients else 'Other'
    tmp['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].mean()
    for col in label_encoders:
        le = label_encoders[col]
        if tmp[col] not in le.classes_ and 'Other' in le.classes_:
            tmp[col] = 'Other'
        elif tmp[col] not in le.classes_:
            tmp[col] = le.classes_[0]
        tmp[col] = le.transform([str(tmp[col])])[0]
    for col in numeric_cols:
        tmp[col] = float(tmp[col])
    tmp_arr = np.array([tmp[col] for col in numeric_cols]).reshape(1, -1)
    tmp_scaled = scaler.transform(tmp_arr)[0]
    for i, col in enumerate(numeric_cols):
        tmp[col] = tmp_scaled[i]
    tmp_X = pd.DataFrame([tmp])[feature_cols]
    y_pred = model.predict(tmp_X.values)
    return float(y_pred[0][0]), "ØªÙˆÙ‚Ø¹"

def save_prediction(data, prediction, source, model_name):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    prediction_df = pd.DataFrame([{
        **data,
        'Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±': prediction,
        'Ù…ØµØ¯Ø±': source,
        'Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„': model_name,
        'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªÙˆÙ‚Ø¹': timestamp
    }])
    prediction_file = os.path.join(PREDICTIONS_DIR, f"predictions_{timestamp}.csv")
    prediction_df.to_csv(prediction_file, index=False, encoding='utf-8-sig')
    return prediction_file

def insight_explanation(row, model_name, models, orig_df):
    tips = ""
    why = ""
    if model_name == "XGBoost":
        tips = (
            "- ÙŠÙØ¶Ù„ ØªØ¹Ø¨Ø¦Ø© ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© (Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ - Ø§Ù„Ù…Ù†ØªØ¬ - ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©).\n"
            "- Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù„Ùˆ Ù…Ù† Ø¶Ù…Ù† Ø§Ù„ØªÙˆØ¨ 10 Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ØªÙˆÙ‚Ø¹ ÙŠÙƒÙˆÙ† Ø£Ø¯Ù‚.\n"
            "- Ø¹ÙˆØ§Ù…Ù„ Ù…Ø«Ù„ Ø§Ù„Ø±Ø¨Ø¹ØŒ Ù…ÙˆØ³Ù… Ø§Ù„ØµÙŠÙØŒ ÙˆÙƒÙ…ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø³Ø§Ø¨Ù‚Ù‹Ø§ ØªØ¤Ø«Ø± Ø¨Ù‚ÙˆØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©.\n"
            "- Ø§Ù„ØªÙˆÙ‚Ø¹ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø¹Ù‚Ø¯Ø© Ø¨ÙŠÙ† ÙƒÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."
        )
        why = (
            f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ØªØ¹ØªÙ…Ø¯ Ø¨Ø´ÙƒÙ„ Ø±Ø¦ÙŠØ³ÙŠ Ø¹Ù„Ù‰ :\n"
            f"- Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ (ØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ {'Ø¹Ù…ÙŠÙ„ Ø±Ø¦ÙŠØ³ÙŠ' if row['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] in models['xgboost'][5] else 'Ø¹Ù…ÙŠÙ„ Ø¹Ø§Ø¯ÙŠ'})\n"
            f"- Ø§Ù„Ù…Ù†ØªØ¬: {row['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬']}\n"
            f"- Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø³Ù†Ø©: {row['Ø§Ù„Ø´Ù‡Ø±']}/{row['Ø§Ù„Ø³Ù†Ø©']}\n"
            f"- Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨ Ùˆ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…ÙŠÙ„ Ùˆ Ø§Ù„Ù…Ù†ØªØ¬\n"
            f"- { 'Ø§Ù„ØµÙŠÙ' if row['Ø§Ù„Ø´Ù‡Ø±'] in [6,7,8,9] else 'Ø®Ø§Ø±Ø¬ Ù…ÙˆØ³Ù… Ø§Ù„ØµÙŠÙ'}\n"
            "Ù‚ÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ù…Ø±Øª Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ¹Ù„Ù… Ù…Ù†Ù‡Ø§ Ù†Ù…Ø· Ø§Ù„Ø·Ù„Ø¨ ÙˆØ§Ù„ØªØºÙŠØ±Ø§Øª."
        )
    elif model_name == "ARIMA":
        tips = (
            "- Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø§Ø³Ø¨ Ø£ÙƒØ«Ø± Ù„Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© (Ù…Ø«Ù„Ø§Ù‹ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø´Ù‡Ø±ÙŠ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ù„ÙŠØ¨ÙŠØ§ ÙƒÙ„Ù‡Ø§).\n"
            "- Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ù„Ù…Ø§ ÙŠÙƒÙˆÙ† ÙÙŠÙ‡ Ø§Ù†ØªØ¸Ø§Ù… ØªØ§Ø±ÙŠØ®ÙŠ ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„ÙƒÙ…ÙŠØ§Øª.\n"
            "- Ù„Ø§ ÙŠÙ‡ØªÙ… Ø¨ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø£Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ØŒ ÙÙ‚Ø· Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø³Ù†Ø©/Ø§Ù„Ø´Ù‡Ø±) ØªØ¤Ø«Ø± ÙÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø©."
        )
        why = (
            f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø­ØªÙ‰ ØªØ§Ø±ÙŠØ® {row['Ø§Ù„Ø´Ù‡Ø±']}/{row['Ø§Ù„Ø³Ù†Ø©']}.\n"
            "Ù„Ùˆ Ø§Ù„Ø´Ù‡Ø± Ø£Ùˆ Ø§Ù„Ø³Ù†Ø© Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ¯Ù‘ÙŠÙƒ Ù…ØªÙˆØ³Ø· Ø£Ùˆ ØªÙ†Ø¨Ø¤ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©."
        )
    elif model_name == "ANN":
        tips = (
            "- Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ ÙŠØ­Ù„Ù„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ØºÙŠØ± Ø§Ù„Ø®Ø·ÙŠØ© ÙÙŠ ÙƒÙ„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„.\n"
            "- Ø­Ø§ÙˆÙ„ Ù…Ù„Ø¡ ÙƒÙ„ Ø§Ù„Ø®Ø§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù„Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø§Ø³ Ù„Ø£ÙŠ ØªØºÙŠÙŠØ±.\n"
            "- ÙŠÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ ØºØ±ÙŠØ¨Ø© Ø£Ùˆ Ù…Ø¹Ù‚Ø¯Ø© Ù…Ø§ ØªØªÙØ³Ø±Ø´ Ø¨Ø§Ù„Ø³Ù‡ÙˆÙ„Ø©."
        )
        why = (
            f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ù†Ø§ØªØ¬Ø© Ø¹Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ø§Ù„Ø¹Ù…ÙŠÙ„ - Ø§Ù„Ù…Ù†ØªØ¬ - Ø§Ù„Ø´Ù‡Ø± - ÙƒÙ„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©)\n"
            "Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø£Ø­ÙŠØ§Ù†Ø§ ØªÙƒØªØ´Ù Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø®ÙÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙŠØµØ¹Ø¨ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙˆØ¯ÙŠÙ„ Ø¢Ø®Ø± Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§."
        )
    else:
        tips = "Ø§Ø®ØªØ± Ù…ÙˆØ¯ÙŠÙ„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ³ÙŠØ±."
        why = "Ø§Ø®ØªØ± Ù…ÙˆØ¯ÙŠÙ„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ³ÙŠØ±."
    return tips, why

def analyze_prediction(pred_value, df_all, model_name):
    avg = df_all['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].mean()
    q1 = df_all['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.25)
    q3 = df_all['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.75)
    status, msg, color1, color2, icon = "", "", "", "", ""
    if pred_value > q3:
        status = "ÙƒÙ…ÙŠØ© Ù…Ø±ØªÙØ¹Ø© ğŸš¨"
        msg = "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø£ØºÙ„Ø¨ Ø§Ù„Ø·Ù„Ø¨Ø§Øª. ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø­Ø§Ù„Ø© Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ© Ø£Ùˆ Ø·Ù„Ø¨ Ù…ÙˆØ³Ù…ÙŠ ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯."
        color1, color2 = "#F85032", "#FFB347"
        icon = "ğŸ”´"
    elif pred_value < q1:
        status = "ÙƒÙ…ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© â„¹ï¸"
        msg = "Ø§Ù„ÙƒÙ…ÙŠØ© Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø¹ØªØ§Ø¯. Ø±Ø¨Ù…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø°Ù„Ùƒ Ø¨Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©."
        color1, color2 = "#00C9FF", "#92FE9D"
        icon = "ğŸŸ¢"
    else:
        status = "ÙƒÙ…ÙŠØ© Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ ğŸ’¡"
        msg = "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ØªÙ‚Ø¹ Ø¶Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø¹ØªØ§Ø¯. Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø®Ø·ÙˆØ±Ø© Ø­Ø§Ù„ÙŠØ©."
        color1, color2 = "#43cea2", "#185a9d"
        icon = "ğŸŸ "
    return status, msg, color1, color2, icon

def main():
    st.set_page_config(page_title="ØªÙˆÙ‚Ø¹ ÙˆØªØ­Ù„ÙŠÙ„ ÙƒÙ…ÙŠØ© Ø§Ù„Ø¯ÙŠØ²Ù„", layout="wide")
    st.markdown(
        """
        <div style="background: linear-gradient(90deg, #32B67A 10%, #72D7B2 90%);
                    border-radius:2.5rem;
                    padding: 1rem 2.2rem;
                    margin-bottom:1.6rem;
                    box-shadow:0 8px 24px 0 rgba(50,50,93,.09);
                    text-align:center;">
            <span style="font-size:2.6rem; font-weight:900; color:#fff; letter-spacing:2px;">
                ğŸšš ØªÙˆÙ‚Ø¹ ÙƒÙ…ÙŠØ© Ø§Ù„Ø¯ÙŠØ²Ù„ Ø§Ù„Ø°ÙƒÙŠØ©
            </span>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.sidebar.markdown("### Ø±ÙØ¹ Ù…Ù„Ù Ø¥ÙƒØ³Ù„ Ø®Ø§Øµ Ø¨Ùƒ")
    excel_file = st.sidebar.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø¨Ø§Ù„Ù‡ÙŠÙƒÙ„ Ù†ÙØ³Ù‡ (Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©):", type=["xlsx"])
    train_btn = st.sidebar.button("Train / Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª")

    if "user_df" not in st.session_state:
        st.session_state.user_df = None
    if "user_models" not in st.session_state:
        st.session_state.user_models = None

    if train_btn and excel_file:
        try:
            user_df = load_and_preprocess_data(excel_file)
            user_models = prepare_and_train_models(user_df)
            st.session_state.user_df = user_df
            st.session_state.user_models = user_models
            st.sidebar.success("ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­ âœ…")
        except Exception as e:
            st.sidebar.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª: {e}")

    if st.session_state.user_df is not None and st.session_state.user_models is not None:
        orig_df = st.session_state.user_df
        models = st.session_state.user_models
    else:
        orig_df = load_and_preprocess_data("Ø¯ÙŠØ²Ù„ 20-24.xlsx")
        models = prepare_and_train_models(orig_df)
        if orig_df is None:
            return

    page = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„ØµÙØ­Ø©", ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©", "Ø£Ù†Ø³ÙŠØª", "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"])

    if page == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown(render_colored_card(
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ…ÙŠØ©", f"{int(models['xgboost'][6]['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum()):,}", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯ÙŠØ²Ù„ Ø§Ù„Ù…ÙˆØ²Ø¹",
                "#2196F3", "#1565C0", icon="ğŸ›¢"), unsafe_allow_html=True)
        with col2:
            st.markdown(render_colored_card(
                "Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", models["xgboost"][6]["Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†"].nunique(), "Ø¹Ù…Ù„Ø§Ø¡ ÙØ±ÙŠØ¯ÙˆÙ†",
                "#43A047", "#166534", icon="ğŸ‘¤"), unsafe_allow_html=True)
        with col3:
            top_product_row = models["xgboost"][6].groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().idxmax()
            top_product_val = int(models["xgboost"][6].groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().max())
            st.markdown(render_colored_card(
                "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø¨ÙŠØ¹Ù‹Ø§", f"{top_product_row}", f"{top_product_val:,} Ù„ØªØ±",
                "#FFC107", "#FF6F00", icon="ğŸ†"), unsafe_allow_html=True)
        with col4:
            top_customer_row = models["xgboost"][6].groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().idxmax()
            top_customer_val = int(models["xgboost"][6].groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().max())
            st.markdown(render_colored_card(
                "Ø£ÙƒØ¨Ø± Ø¹Ù…ÙŠÙ„", f"{top_customer_row}", f"{top_customer_val:,} Ù„ØªØ±",
                "#EC407A", "#7B1FA2", icon="ğŸ¥‡"), unsafe_allow_html=True)
        col_viz1, col_viz2 = st.columns(2)
        with col_viz1:
            region_counts = models["xgboost"][6]['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'].value_counts()
            fig1 = px.pie(names=region_counts.index, values=region_counts.values, title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚',
                         color_discrete_sequence=px.colors.qualitative.Set3)
            fig1.update_traces(textinfo='percent+label')
            st.plotly_chart(fig1, use_container_width=True)
        with col_viz2:
            fig2 = px.histogram(models["xgboost"][6], x='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±',
                               nbins=20, color_discrete_sequence=['#FF6F61'])
            fig2.update_layout(xaxis_title='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', yaxis_title='Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ')
            st.plotly_chart(fig2, use_container_width=True)
        monthly_avg = models["xgboost"][6].groupby('Ø§Ù„Ø´Ù‡Ø±')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].mean().reset_index()
        fig3 = px.line(monthly_avg, x='Ø§Ù„Ø´Ù‡Ø±', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±',
                      line_shape='spline', color_discrete_sequence=['#43A047'])
        st.plotly_chart(fig3, use_container_width=True)
        top_customers = models["xgboost"][6].groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().nlargest(10).reset_index()
        fig4 = px.bar(top_customers, x='Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ø£Ø¹Ù„Ù‰ 10 Ø¹Ù…Ù„Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ©',
                     color_discrete_sequence=['#FFB300'])
        fig4.update_layout(xaxis_title='Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', yaxis_title='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', xaxis_tickangle=45)
        st.plotly_chart(fig4, use_container_width=True)
        yearly_sum = models["xgboost"][6].groupby('Ø§Ù„Ø³Ù†Ø©')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().reset_index()
        fig5 = px.line(yearly_sum, x='Ø§Ù„Ø³Ù†Ø©', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø³Ù†Ø©',
                      line_shape='spline', color_discrete_sequence=['#8E24AA'])
        st.plotly_chart(fig5, use_container_width=True)

    elif page == "ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©":
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []
        model_choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", options=["XGBoost", "ARIMA", "ANN"])
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)
            with col1:
                region = st.selectbox("Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", options=[1.0, 2.0])
                year = st.number_input("Ø§Ù„Ø³Ù†Ø©", min_value=2020, max_value=2025, step=1, value=2023)
                month = st.number_input("Ø§Ù„Ø´Ù‡Ø±", min_value=1, max_value=12, step=1, value=1)
            with col2:
                account = st.number_input("Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨", min_value=0, step=1, value=170003)
                customer = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†", value="Ù…Ø­Ø·Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¡ØºØ±Ø¨ Ø·Ø±Ø§Ø¨Ù„Ø³")
                product = st.text_input("Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", value="ÙˆÙ‚ÙˆØ¯ Ø§Ù„Ø¯ÙŠØ²Ù„")
                packaging = st.text_input("ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©", value="Ø³Ø§Ø¦Ø¨/Ù„ØªØ±")
            submitted = st.form_submit_button("ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©")
        if submitted:
            if not customer or not product or not packaging:
                st.error("ÙŠØ±Ø¬Ù‰ Ù…Ù„Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„")
            else:
                new_data = pd.DataFrame([{
                    'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©': region,
                    'Ø§Ù„Ø³Ù†Ø©': year,
                    'Ø§Ù„Ø´Ù‡Ø±': month,
                    'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨': account,
                    'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†': customer,
                    'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬': product,
                    'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©': packaging
                }])
                if model_choice == "XGBoost":
                    prediction, source = retrieve_or_predict(
                        new_data.iloc[0], orig_df, models["xgboost"][0], models["xgboost"][1], models["xgboost"][2],
                        models["xgboost"][3], models["xgboost"][4], models["xgboost"][5], models["xgboost"][6]
                    )
                elif model_choice == "ARIMA":
                    prediction, source = predict_arima(
                        new_data.iloc[0], models["arima"][0], models["arima"][1]
                    )
                elif model_choice == "ANN":
                    prediction, source = predict_ann(
                        new_data.iloc[0], models["ann"][0], models["ann"][1], models["ann"][2], models["ann"][3], models["ann"][4], models["ann"][5], models["ann"][6]
                    )
                prediction_file = save_prediction(new_data.iloc[0], prediction, source, model_choice)
                st.session_state.prediction_history.append({
                    **new_data.iloc[0],
                    'Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±': prediction,
                    'Ù…ØµØ¯Ø±': source,
                    'Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„': model_choice
                })
                st.markdown(render_colored_card(
                    "ğŸ”¥ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", f"{prediction:,.2f} Ù„ØªØ±", f"Ø§Ù„Ù…ØµØ¯Ø±: {source} - {model_choice}",
                    "#57C1EB", "#246FA8", radius="2.5rem", icon="â›½"
                ), unsafe_allow_html=True)
                with open(prediction_file, 'rb') as f:
                    st.download_button(
                        label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹",
                        data=f,
                        file_name=os.path.basename(prediction_file),
                        mime="text/csv"
                    )
        if st.session_state.prediction_history:
            st.markdown(
                '<div style="font-size:1.6rem; font-weight:700; color:#1565C0; margin-bottom:1rem;">Ø³Ø¬Ù„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª</div>',
                unsafe_allow_html=True
            )
            history_df = pd.DataFrame(st.session_state.prediction_history)
            st.dataframe(history_df, use_container_width=True)

    elif page == "Ø£Ù†Ø³ÙŠØª":
        st.markdown(
            '<div style="font-size:2.0rem; font-weight:800; color:#2196F3; margin-bottom:1.2rem; text-align:center;">ğŸ§  ØµÙØ­Ø© Ø£Ù†Ø³ÙŠØª - Ø´Ø±Ø­ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª</div>',
            unsafe_allow_html=True
        )
        if 'prediction_history' in st.session_state and len(st.session_state.prediction_history) > 0:
            history_df = pd.DataFrame(st.session_state.prediction_history)
            selected_index = st.selectbox(
                "Ø§Ø®ØªØ± ØªÙˆÙ‚Ø¹ Ù„Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„Ù‡:",
                options=list(range(len(history_df))),
                format_func=lambda i: f"{history_df.iloc[i]['Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„']} | {history_df.iloc[i]['Ø§Ù„Ø³Ù†Ø©']}/{history_df.iloc[i]['Ø§Ù„Ø´Ù‡Ø±']} | {history_df.iloc[i]['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†']}"
            )
            selected_pred = history_df.iloc[selected_index]
            status, msg, c1, c2, icon = analyze_prediction(selected_pred['Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±'], models["xgboost"][6], selected_pred['Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„'])
            st.markdown(f"""
                <div style='margin: 1.2rem 0 1.6rem 0; padding: 1.2rem 2.2rem 1.7rem 2.2rem; 
                            background: linear-gradient(90deg, {c1} 30%, {c2} 100%);
                            border-radius: 2.1rem; color: #fff; font-size:1.13rem; font-weight: 600; letter-spacing:1.1px; box-shadow:0 4px 32px 0 rgba(50,50,93,.09);'>
                <span style="font-size:1.15rem; font-weight:800; color:#fff;">ØªÙØµÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹</span><br>
                Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: <span style="font-size:1.25rem;color:#fff;font-weight:900;">{selected_pred['Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±']:.2f} Ù„ØªØ±</span><br>
                Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: <span style="font-size:1.05rem;font-weight:800;">{selected_pred['Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„']}</span><br>
                Ø§Ù„Ù…ØµØ¯Ø±: <span style="font-size:1.01rem;">{selected_pred['Ù…ØµØ¯Ø±']}</span><br>
                <hr style='margin: 0.7rem 0 0.6rem 0; border-color: #fff;'>
                <span style="font-size:1.04rem;">{icon} <b>{status}</b></span>
                <br><span style="font-size:0.99rem;">{msg}</span>
                </div>
            """, unsafe_allow_html=True)
            tips, why = insight_explanation(selected_pred, selected_pred['Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„'], models, orig_df)
            st.markdown(f"#### <span style='color:#1976D2;'>ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù‡Ø§Ù…Ø©</span>", unsafe_allow_html=True)
            st.markdown(
                f"<div style='background: #192C3A; color:#d5e5f7; padding: 1rem 1.7rem; border-radius: 1.1rem; font-size:1.07rem;'>{tips.replace('-', 'â€¢')}</div>",
                unsafe_allow_html=True
            )
            st.markdown(f"#### <span style='color:#F57C00;'>ğŸ¤” Ù„Ù…Ø§Ø°Ø§ Ù‡Ø°Ø§ Ø§Ù„ØªÙˆÙ‚Ø¹ØŸ</span>", unsafe_allow_html=True)
            st.markdown(
                f"<div style='background: #1A2636; color:#fff; padding: 1rem 1.7rem; border-radius: 1.1rem; font-size:1.07rem;'>{why.replace('-', 'â€¢')}</div>",
                unsafe_allow_html=True
            )
            st.markdown("### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø±Ø³ÙˆÙ…ÙŠØ© Ù„Ù„ØªÙˆÙ‚Ø¹")
            import plotly.graph_objs as go
            d = models["xgboost"][6]
            pred_val = selected_pred['Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±']
            selected_month = f"{selected_pred['Ø§Ù„Ø³Ù†Ø©']}-{selected_pred['Ø§Ù„Ø´Ù‡Ø±']}"
            customer_data = d[d['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] == selected_pred['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†']].sort_values(['Ø§Ù„Ø³Ù†Ø©','Ø§Ù„Ø´Ù‡Ø±'])
            st.markdown("#### ğŸ”µ ØªØ·ÙˆØ± Ø·Ù„Ø¨Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†")
            if not customer_data.empty:
                time_labels = customer_data['Ø§Ù„Ø³Ù†Ø©'].astype(str) + "-" + customer_data['Ø§Ù„Ø´Ù‡Ø±'].astype(str)
                fig1 = go.Figure()
                fig1.add_trace(go.Scatter(
                    x=time_labels,
                    y=customer_data['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'],
                    mode='lines+markers',
                    name='Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©',
                    line=dict(color='rgba(50,140,255,0.8)', width=2),
                    marker=dict(size=10, color='rgba(12,45,130,0.85)', line=dict(width=2, color="#fff")),
                    hoverlabel=dict(bgcolor="#222", font=dict(color="#fff")),
                ))
                fig1.add_trace(go.Scatter(
                    x=[selected_month],
                    y=[pred_val],
                    mode='markers+text',
                    name="ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„",
                    marker=dict(size=18, color="orange", line=dict(width=4, color="#fff")),
                    text=["ØªÙˆÙ‚Ø¹"], textposition="top center"
                ))
                fig1.update_layout(
                    title="Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø´Ù‡Ø±ÙŠØ© ÙˆØªÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„",
                    xaxis_title="Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø³Ù†Ø©",
                    yaxis_title="Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±",
                    plot_bgcolor="#232936",
                    paper_bgcolor="#232936",
                    font=dict(color="#F9FAFB", size=14),
                    xaxis=dict(tickangle=-45, showgrid=False),
                    yaxis=dict(showgrid=True, gridcolor="#39414e"),
                    legend=dict(bgcolor="#222831", font=dict(size=13)),
                    height=320,
                    margin=dict(l=30, r=30, t=40, b=80),
                )
                st.plotly_chart(fig1, use_container_width=True)
                st.markdown(
                    "<span style='color:#6AD49B; font-size:1.1rem;'>Ø§Ù„Ø±Ø³Ù… ÙŠÙˆØ¶Ø­ ØªØ·ÙˆØ± ÙƒÙ…ÙŠØ§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ ÙˆØ§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠØ© ØªÙ…Ø«Ù„ ØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ. Ù„Ùˆ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¨Ø¹ÙŠØ¯ Ø¹Ù† Ø§Ù„Ø®Ø· Ø§Ù„Ø£Ø²Ø±Ù‚ Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ØŒ Ù‡Ø°Ø§ Ù…Ø¹Ù†Ø§Ù‡ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙˆÙ‚Ø¹ ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ®.</span>",
                    unsafe_allow_html=True
                )
            else:
                st.info("Ø§Ù„Ø¹Ù…ÙŠÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ù„Ø¨Ø§Øª.")
            st.markdown("#### ğŸŸ¢ ØªØ·ÙˆØ± Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„ÙƒÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù…Ø¹ Ø¥Ø¨Ø±Ø§Ø² ØªÙˆÙ‚Ø¹Ùƒ")
            monthly_avg = d.groupby(['Ø§Ù„Ø³Ù†Ø©','Ø§Ù„Ø´Ù‡Ø±'])['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].mean().reset_index()
            monthly_avg['ØªØ§Ø±ÙŠØ®'] = monthly_avg['Ø§Ù„Ø³Ù†Ø©'].astype(str) + "-" + monthly_avg['Ø§Ù„Ø´Ù‡Ø±'].astype(str)
            fig2 = go.Figure()
            fig2.add_trace(go.Scatter(
                x=monthly_avg['ØªØ§Ø±ÙŠØ®'],
                y=monthly_avg['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'],
                mode='lines+markers',
                name='Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠØ©',
                line=dict(color='#36C1A2', width=3),
                marker=dict(size=8, color='#23353F', line=dict(width=2, color="#fff")),
                hoverlabel=dict(bgcolor="#222", font=dict(color="#fff")),
            ))
            fig2.add_trace(go.Scatter(
                x=[selected_month],
                y=[pred_val],
                mode="markers+text",
                name="ØªÙˆÙ‚Ø¹Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ",
                marker=dict(size=18, color="#FF8333", line=dict(width=4, color="#fff")),
                text=["ØªÙˆÙ‚Ø¹"], textposition="bottom center"
            ))
            fig2.update_layout(
                title="Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
                xaxis_title="Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø³Ù†Ø©",
                yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±",
                plot_bgcolor="#222831",
                paper_bgcolor="#222831",
                font=dict(color="#F9FAFB", size=14),
                xaxis=dict(tickangle=-45, showgrid=False),
                yaxis=dict(showgrid=True, gridcolor="#313C47"),
                legend=dict(bgcolor="#222831", font=dict(size=13)),
                height=320,
                margin=dict(l=30, r=30, t=40, b=80),
            )
            st.plotly_chart(fig2, use_container_width=True)
            st.markdown(
                "<span style='color:#A4CEFC; font-size:1.1rem;'>Ø§Ù„Ø±Ø³Ù… ÙŠØ¹Ø±Ø¶ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ØŒ Ù…Ø¹ Ø¥Ø¨Ø±Ø§Ø² Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ. Ù‡Ø°Ø§ ÙŠØ³Ø§Ø¹Ø¯Ùƒ ØªØ´ÙˆÙ Ø¥Ø°Ø§ ÙƒØ§Ù† ØªÙˆÙ‚Ø¹Ùƒ Ø£Ø¹Ù„Ù‰ Ø£Ùˆ Ø£Ù‚Ù„ Ø£Ùˆ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚.</span>",
                unsafe_allow_html=True
            )
        else:
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙˆÙ‚Ø¹Ø§Øª Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†. Ø§Ø¨Ø¯Ø£ Ø£ÙˆÙ„Ù‹Ø§ Ù…Ù† ØµÙØ­Ø© 'ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©'.")

    elif page == "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬":
        st.markdown(
            """
            <div style="background: linear-gradient(90deg,#43cea2 10%,#185a9d 90%);
                        border-radius:2rem;padding:1rem 2rem;margin-bottom:1.3rem;text-align:center;">
                <span style="font-size:2.2rem; font-weight:900; color:#fff;">ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø«Ù„Ø§Ø«Ø©</span>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.markdown("### ğŸ“Š Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""
            <div style="background:#e3f1fb;border-radius:1.3rem;padding:1.25rem 1.1rem 1.2rem 1.1rem;">
            <b style='color:#1565C0;font-size:1.18rem;'>XGBoost</b><br>
            <span style='color:#223;'>â€¢ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø£Ø´Ø¬Ø§Ø± ØªØ¹Ø²ÙŠØ²ÙŠØ© (Gradient Boosting Trees)<br>
            â€¢ Ù‚ÙˆÙŠØ© Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ù…ØªØ¹Ø¯Ø¯Ø©.<br>
            â€¢ ØªØµÙ„Ø­ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø¹Ù‚Ø¯Ø© ÙˆØºÙŠØ± Ø®Ø·ÙŠØ©.<br></span>
            </div>
            """, unsafe_allow_html=True)
        with col2:
            st.markdown("""
            <div style="background:#fff6e3;border-radius:1.3rem;padding:1.25rem 1.1rem 1.2rem 1.1rem;">
            <b style='color:#D84315;font-size:1.18rem;'>ARIMA</b><br>
            <span style='color:#332;'>â€¢ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ© ÙÙ‚Ø·.<br>
            â€¢ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ø³Ù„Ø³Ù„Ø©.<br>
            â€¢ Ù…Ù…ØªØ§Ø² Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„ÙƒÙ„ÙŠ Ø£Ùˆ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ Ø¹Ø¨Ø± Ø§Ù„ÙˆÙ‚Øª.<br></span>
            </div>
            """, unsafe_allow_html=True)
        with col3:
            st.markdown("""
            <div style="background:#f7f2ff;border-radius:1.3rem;padding:1.25rem 1.1rem 1.2rem 1.1rem;">
            <b style='color:#7B1FA2;font-size:1.18rem;'>ANN</b><br>
            <span style='color:#232;'>â€¢ Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© (Artificial Neural Network).<br>Ø¨
            â€¢ ØªØªØ¹Ù„Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø®ÙÙŠØ© Ø¨ÙŠÙ† ÙƒÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª.<br>
            â€¢ Ù…Ù…ØªØ§Ø²Ø© ÙÙŠ Ø­Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø© ÙˆØ£Ù†Ù…Ø§Ø· Ù…Ø¹Ù‚Ø¯Ø©.<br></span>
            </div>
            """, unsafe_allow_html=True)


        st.markdown("---")
        st.markdown("### ğŸ§® Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª ÙˆÙÙƒØ±Ø© Ø§Ù„Ø¹Ù…Ù„")
        with st.expander("ğŸ”¹ Ù…Ø¹Ø§Ø¯Ù„Ø©/Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© XGBoost"):
            st.latex(r"""
                \hat{y}_i = \sum_{k=1}^{K} f_k(x_i), \quad f_k \in \mathcal{F}
            """)
            st.markdown(
                "ÙƒÙ„ Ø´Ø¬Ø±Ø© Ù‚Ø±Ø§Ø± (Tree) ØªØªØ¹Ù„Ù… ØªØµØ­ÙŠØ­ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø¬Ø±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹ Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±."
            )
        with st.expander("ğŸ”¸ Ù…Ø¹Ø§Ø¯Ù„Ø© ARIMA (Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ)"):
            st.latex(r"""
                y_t = c + \phi_1 y_{t-1} + ... + \phi_p y_{t-p} + \theta_1 \epsilon_{t-1} + ... + \theta_q \epsilon_{t-q} + \epsilon_t
            """)
            st.markdown(
                "ARIMA ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ø³Ù„Ø³Ù„Ø© (y) ÙˆØ¹Ù„Ù‰ Ø§Ù„ØªØ´ÙˆÙŠØ´ (Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡) Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©."
            )
        with st.expander("ğŸ”º Ù…Ø¹Ø§Ø¯Ù„Ø© ANN (Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©)"):
            st.latex(r"""
                \mathbf{y} = \sigma(\mathbf{W}_2 \cdot \sigma(\mathbf{W}_1 \cdot \mathbf{x} + \mathbf{b}_1) + \mathbf{b}_2)
            """)
            st.markdown(
                "Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© ØªØªÙƒÙˆÙ† Ù…Ù† Ø·Ø¨Ù‚Ø§Øª Ù…ØªØµÙ„Ø©ØŒ ÙˆÙƒÙ„ Ø·Ø¨Ù‚Ø© ØªØ·Ø¨Ù‚ ØªØ­ÙˆÙŠÙ„Ø§Øª ØºÙŠØ± Ø®Ø·ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØªØªØ¹Ù„Ù… Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨."
            )

        st.markdown("---")
        st.markdown("### âš–ï¸ Ù…Ù…ÙŠØ²Ø§Øª ÙˆØ¹ÙŠÙˆØ¨ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬")
        st.markdown("""
        | Ø§Ù„Ù†Ù…ÙˆØ°Ø¬    | Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª         | Ø§Ù„Ø¹ÙŠÙˆØ¨              |
        |:----------:|:----------------|:---------------------|
        | **XGBoost** | Ø¯Ù‚ÙŠÙ‚ ÙˆØ³Ø±ÙŠØ¹ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©ØŒ ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø¹Ù‚Ø¯Ø©ØŒ Ù…Ù‚Ø§ÙˆÙ… Ù„Ù€ overfitting | ÙŠØ­ØªØ§Ø¬ Ø¶Ø¨Ø· Ø¬ÙŠØ¯ Ù„Ù„Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø§ØªØŒ Ù„ÙŠØ³ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© ÙÙ‚Ø· |
        | **ARIMA**  | Ø³Ù‡Ù„ Ø§Ù„ØªÙØ³ÙŠØ±ØŒ Ù…Ù…ØªØ§Ø² Ù„Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØŒ Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø®ØµØ§Ø¦Øµ ÙƒØ«ÙŠØ±Ø© | Ù„Ø§ ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…ØªØºÙŠØ±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©ØŒ ÙŠØ­ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ÙƒØ§ÙÙŠØ© |
        | **ANN**    | ÙŠØªØ¹Ù„Ù… Ø£ÙŠ Ø¹Ù„Ø§Ù‚Ø© Ù…Ù‡Ù…Ø§ ÙƒØ§Ù†Øª Ù…Ø¹Ù‚Ø¯Ø©ØŒ Ø¬ÙŠØ¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø© | ÙŠØ­ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ«ÙŠØ±Ø© ÙˆØªØ¯Ø±ÙŠØ¨ Ù‚ÙˆÙŠØŒ Ø£Ù‚Ù„ Ø´ÙØ§ÙÙŠØ© ÙÙŠ Ø§Ù„ØªÙØ³ÙŠØ±  |
        """)

        st.markdown("---")
        st.markdown("### ğŸ“š Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯ÙˆÙƒÙ…Ù†ØªØ´Ù† Ø§Ù„Ø±Ø³Ù…ÙŠØ©")
        st.markdown("""
        - [ğŸ”— XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/)
        - [ğŸ”— ARIMA (statsmodels) Documentation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html)
        - [ğŸ”— Keras / ANN Documentation](https://keras.io/api/models/sequential/)
        """)

        st.info(
            "Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø­Ø³Ø¨ Ø·Ø¨ÙŠØ¹Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙˆØ§Ù„ØºØ±Ø¶ Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹. Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±ØŒ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø²ÙŠØ¯."
        )

if __name__ == "__main__":
    main()
