import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import os
import joblib
import plotly.express as px
import streamlit as st
import datetime

# --------------------- ÙƒØ§Ø±Øª Ù…Ù„ÙˆÙ‘Ù† Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ---------------------
def render_colored_card(title, value, subtitle, color1, color2, radius="2.2rem", icon=""):
    return f"""
    <div style="
        border-radius: {radius};
        background: linear-gradient(135deg, {color1} 0%, {color2} 100%);
        box-shadow: 0 4px 32px 0 rgba(50,50,93,.08), 0 1.5px 2.5px 0 rgba(0,0,0,.07);
        padding: 2rem 1.5rem 1.5rem 1.5rem;
        margin-bottom: 1.8rem;
        text-align:center;
        position:relative;
    ">
        <div style='font-size:2.1rem; font-weight:800; color:#fff; letter-spacing:1.5px; margin-bottom:0.5rem;'>{icon} {title}</div>
        <div style='font-size:2.2rem; font-weight:700; color:#222; margin-bottom:0.7rem;'>{value}</div>
        <div style='font-size:1.1rem; color:#fff; letter-spacing:1.1px'>{subtitle}</div>
    </div>
    """

MODEL_DIR = "model_artifacts"
PREDICTIONS_DIR = "predictions"
for directory in [MODEL_DIR, PREDICTIONS_DIR]:
    if not os.path.exists(directory):
        os.makedirs(directory)

def load_and_preprocess_data(file_path):
    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
        return None
    cols_to_drop = list(range(8, 28))
    df = df.drop(df.columns[cols_to_drop], axis=1)
    df = df.dropna(subset=['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©'])
    for col in ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']:
        df[col] = df[col].astype(str).str.strip()
    unknown_indices = df[df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] == 'Unknown'].index
    n_unknown = len(unknown_indices)
    regions = [1.0, 2.0]
    assigned_regions = np.tile(regions, int(np.ceil(n_unknown / len(regions))))[:n_unknown]
    np.random.shuffle(assigned_regions)
    df.loc[unknown_indices, 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'] = assigned_regions
    return df

def prepare_and_train_model(df):
    Q1 = df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.25)
    Q3 = df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_clean = df[(df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'] >= lower_bound) & (df['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'] <= upper_bound)].copy()
    df_clean['Ø§Ù„Ø±Ø¨Ø¹'] = ((df_clean['Ø§Ù„Ø´Ù‡Ø±'] - 1) // 3 + 1).astype(int)
    df_clean['Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ'] = df_clean['Ø§Ù„Ø´Ù‡Ø±'].apply(lambda x: 1 if x in [6, 7, 8, 9] else 0)
    df_clean['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].transform('count')
    df_clean['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'].transform('count')
    top_clients = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].value_counts().nlargest(10).index
    df_clean['Ø§Ù„Ø¹Ù…ÙŠÙ„_Top'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].apply(lambda x: x if x in top_clients else 'Other')
    df_clean = df_clean.sort_values(['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±'])
    df_clean['ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].shift(1)
    df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = np.log1p(df_clean['ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'])
    df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].fillna(df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].mean())
    label_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©', 'Ø§Ù„Ø¹Ù…ÙŠÙ„_Top']
    label_encoders = {}
    for col in label_cols:
        df_clean[col] = df_clean[col].astype(str).str.strip()
        le = LabelEncoder()
        df_clean[col] = le.fit_transform(df_clean[col])
        label_encoders[col] = le
        joblib.dump(le, os.path.join(MODEL_DIR, f"{col}_encoder.pkl"))
    numeric_cols = ['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ù„Ø±Ø¨Ø¹', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬', 'log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©']
    scaler = StandardScaler()
    df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])
    joblib.dump(scaler, os.path.join(MODEL_DIR, "scaler.pkl"))
    feature_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©', 'Ø§Ù„Ø¹Ù…ÙŠÙ„_Top', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±',
                    'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ù„Ø±Ø¨Ø¹', 'Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„', 'ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬', 'log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©']
    X = df_clean[feature_cols]
    y = df_clean['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = XGBRegressor(n_estimators=150, max_depth=5, learning_rate=0.05, random_state=42,
                        reg_alpha=1.0, reg_lambda=1.0)
    model.fit(X_train, y_train)
    joblib.dump(model, os.path.join(MODEL_DIR, "xgboost_model.pkl"))
    y_pred = model.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)
    return model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean, rmse, r2

def retrieve_or_predict(row, orig_df, model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean):
    row = row.copy()
    for col in ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']:
        row[col] = str(row[col]).strip()
    row['Ø§Ù„Ø³Ù†Ø©'] = int(row['Ø§Ù„Ø³Ù†Ø©'])
    row['Ø§Ù„Ø´Ù‡Ø±'] = int(row['Ø§Ù„Ø´Ù‡Ø±'])
    row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'] = int(row['Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨'])
    lookup_cols = ['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©', 'Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„Ø´Ù‡Ø±', 'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨', 'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©']
    matched = orig_df
    for col in lookup_cols:
        matched = matched[matched[col] == row[col]]
    if not matched.empty:
        return float(matched.iloc[0]['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±']), "Ø§Ø³ØªØ±Ø¬Ø§Ø¹"
    tmp = row.copy()
    tmp['Ø§Ù„Ø±Ø¨Ø¹'] = ((tmp['Ø§Ù„Ø´Ù‡Ø±'] - 1) // 3 + 1)
    tmp['Ù…ÙˆØ³Ù…_Ø§Ù„ØµÙŠÙ'] = 1 if tmp['Ø§Ù„Ø´Ù‡Ø±'] in [6, 7, 8, 9] else 0
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ø¹Ù…ÙŠÙ„'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'], 1)
    tmp['ØªÙƒØ±Ø§Ø±_Ø§Ù„Ù…Ù†ØªØ¬'] = df_clean['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'].value_counts().get(tmp['Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'], 1)
    tmp['Ø§Ù„Ø¹Ù…ÙŠÙ„_Top'] = tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] if tmp['Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†'] in top_clients else 'Other'
    tmp['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'] = df_clean['log_ÙƒÙ…ÙŠØ©_Ø³Ø§Ø¨Ù‚Ø©'].mean()
    for col in label_encoders:
        le = label_encoders[col]
        if tmp[col] not in le.classes_ and 'Other' in le.classes_:
            tmp[col] = 'Other'
        elif tmp[col] not in le.classes_:
            tmp[col] = le.classes_[0]
        tmp[col] = le.transform([str(tmp[col])])[0]
    for col in numeric_cols:
        tmp[col] = float(tmp[col])
    tmp_arr = np.array([tmp[col] for col in numeric_cols]).reshape(1, -1)
    tmp_scaled = scaler.transform(tmp_arr)[0]
    for i, col in enumerate(numeric_cols):
        tmp[col] = tmp_scaled[i]
    tmp_X = pd.DataFrame([tmp])[feature_cols]
    return float(model.predict(tmp_X)[0]), "ØªÙˆÙ‚Ø¹"

def save_prediction(data, prediction, source):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    prediction_df = pd.DataFrame([{
        **data,
        'Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±': prediction,
        'Ù…ØµØ¯Ø±': source,
        'ØªØ§Ø±ÙŠØ®_Ø§Ù„ØªÙˆÙ‚Ø¹': timestamp
    }])
    prediction_file = os.path.join(PREDICTIONS_DIR, f"predictions_{timestamp}.csv")
    prediction_df.to_csv(prediction_file, index=False, encoding='utf-8-sig')
    return prediction_file

# -------------------- ÙˆØ§Ø¬Ù‡Ø© Streamlit Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© --------------------
def main():
    st.set_page_config(page_title="ØªÙˆÙ‚Ø¹ ÙˆØªØ­Ù„ÙŠÙ„ ÙƒÙ…ÙŠØ© Ø§Ù„Ø¯ÙŠØ²Ù„", layout="wide")

    # Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨
    st.markdown(
        """
        <div style="background: linear-gradient(90deg, #32B67A 10%, #72D7B2 90%);
                    border-radius:2.5rem;
                    padding: 1rem 2.2rem;
                    margin-bottom:1.6rem;
                    box-shadow:0 8px 24px 0 rgba(50,50,93,.09);
                    text-align:center;">
            <span style="font-size:2.6rem; font-weight:900; color:#fff; letter-spacing:2px;">
                ğŸšš ØªÙˆÙ‚Ø¹ ÙƒÙ…ÙŠØ© Ø§Ù„Ø¯ÙŠØ²Ù„ Ø§Ù„Ø°ÙƒÙŠØ©
            </span>
        </div>
        """,
        unsafe_allow_html=True
    )

    orig_df = load_and_preprocess_data("Ø¯ÙŠØ²Ù„ 20-24.xlsx")
    if orig_df is None:
        return
    model, label_encoders, scaler, feature_cols, numeric_cols, top_clients, df_clean, rmse, r2 = prepare_and_train_model(orig_df)

    page = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„ØµÙØ­Ø©", ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©"])

    if page == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown(render_colored_card(
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ…ÙŠØ©", f"{int(df_clean['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum()):,}", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯ÙŠØ²Ù„ Ø§Ù„Ù…ÙˆØ²Ø¹",
                "#2196F3", "#1565C0", icon="ğŸ›¢ï¸"), unsafe_allow_html=True)
        with col2:
            st.markdown(render_colored_card(
                "Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", df_clean["Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†"].nunique(), "Ø¹Ù…Ù„Ø§Ø¡ ÙØ±ÙŠØ¯ÙˆÙ†",
                "#43A047", "#166534", icon="ğŸ‘¤"), unsafe_allow_html=True)
        with col3:
            # Ø£ÙƒØ«Ø± Ù…Ù†ØªØ¬
            top_product_row = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().idxmax()
            top_product_val = int(df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().max())
            st.markdown(render_colored_card(
                "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø¨ÙŠØ¹Ù‹Ø§", f"{top_product_row}", f"{top_product_val:,} Ù„ØªØ±",
                "#FFC107", "#FF6F00", icon="ğŸ†"), unsafe_allow_html=True)
        with col4:
            # Ø£ÙƒØ«Ø± Ø¹Ù…ÙŠÙ„
            top_customer_row = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().idxmax()
            top_customer_val = int(df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().max())
            st.markdown(render_colored_card(
                "Ø£ÙƒØ¨Ø± Ø¹Ù…ÙŠÙ„", f"{top_customer_row}", f"{top_customer_val:,} Ù„ØªØ±",
                "#EC407A", "#7B1FA2", icon="ğŸ¥‡"), unsafe_allow_html=True)

        # Pie chart and histogram
        col_viz1, col_viz2 = st.columns(2)
        with col_viz1:
            region_counts = df_clean['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'].value_counts()
            fig1 = px.pie(names=region_counts.index, values=region_counts.values, title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚',
                         color_discrete_sequence=px.colors.qualitative.Set3)
            fig1.update_traces(textinfo='percent+label')
            st.plotly_chart(fig1, use_container_width=True)
        with col_viz2:
            fig2 = px.histogram(df_clean, x='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±',
                               nbins=20, color_discrete_sequence=['#FF6F61'])
            fig2.update_layout(xaxis_title='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', yaxis_title='Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ')
            st.plotly_chart(fig2, use_container_width=True)
        # Monthly trend
        monthly_avg = df_clean.groupby('Ø§Ù„Ø´Ù‡Ø±')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].mean().reset_index()
        fig3 = px.line(monthly_avg, x='Ø§Ù„Ø´Ù‡Ø±', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±',
                      line_shape='spline', color_discrete_sequence=['#43A047'])
        st.plotly_chart(fig3, use_container_width=True)
        # Top customers
        top_customers = df_clean.groupby('Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().nlargest(10).reset_index()
        fig4 = px.bar(top_customers, x='Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ø£Ø¹Ù„Ù‰ 10 Ø¹Ù…Ù„Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ©',
                     color_discrete_sequence=['#FFB300'])
        fig4.update_layout(xaxis_title='Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†', yaxis_title='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', xaxis_tickangle=45)
        st.plotly_chart(fig4, use_container_width=True)
        # Yearly trend
        yearly_sum = df_clean.groupby('Ø§Ù„Ø³Ù†Ø©')['Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±'].sum().reset_index()
        fig5 = px.line(yearly_sum, x='Ø§Ù„Ø³Ù†Ø©', y='Ø§Ù„ÙƒÙ…ÙŠØ© Ø¨Ø§Ù„Ù„ØªØ±', title='Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø³Ù†Ø©',
                      line_shape='spline', color_discrete_sequence=['#8E24AA'])
        st.plotly_chart(fig5, use_container_width=True)

    else:
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)
            with col1:
                region = st.selectbox("Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", options=[1.0, 2.0])
                year = st.number_input("Ø§Ù„Ø³Ù†Ø©", min_value=2020, max_value=2025, step=1, value=2023)
                month = st.number_input("Ø§Ù„Ø´Ù‡Ø±", min_value=1, max_value=12, step=1, value=1)
            with col2:
                account = st.number_input("Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨", min_value=0, step=1, value=170003)
                customer = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†", value="Ù…Ø­Ø·Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¡ØºØ±Ø¨ Ø·Ø±Ø§Ø¨Ù„Ø³")
                product = st.text_input("Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", value="ÙˆÙ‚ÙˆØ¯ Ø§Ù„Ø¯ÙŠØ²Ù„")
                packaging = st.text_input("ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©", value="Ø³Ø§Ø¦Ø¨/Ù„ØªØ±")
            submitted = st.form_submit_button("ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ…ÙŠØ©")
        if submitted:
            if not customer or not product or not packaging:
                st.error("ÙŠØ±Ø¬Ù‰ Ù…Ù„Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„")
            else:
                new_data = pd.DataFrame([{
                    'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©': region,
                    'Ø§Ù„Ø³Ù†Ø©': year,
                    'Ø§Ù„Ø´Ù‡Ø±': month,
                    'Ø±Ù‚Ù… Ø§Ù„Ø­Ø³Ø§Ø¨': account,
                    'Ø§Ø³Ù… Ø§Ù„Ø²Ø¨ÙˆÙ†': customer,
                    'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬': product,
                    'ÙˆØµÙ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©': packaging
                }])
                prediction, source = retrieve_or_predict(
                    new_data.iloc[0], orig_df, model, label_encoders, scaler,
                    feature_cols, numeric_cols, top_clients, df_clean
                )
                prediction_file = save_prediction(new_data.iloc[0], prediction, source)
                st.session_state.prediction_history.append({
                    **new_data.iloc[0],
                    'Ø§Ù„ÙƒÙ…ÙŠØ©_Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©_Ø¨Ø§Ù„Ù„ØªØ±': prediction,
                    'Ù…ØµØ¯Ø±': source
                })
                st.markdown(render_colored_card(
                    "ğŸ”¥ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", f"{prediction:,.2f} Ù„ØªØ±", f"Ø§Ù„Ù…ØµØ¯Ø±: {source}",
                    "#57C1EB", "#246FA8", radius="2.5rem", icon="â›½ï¸"
                ), unsafe_allow_html=True)
                with open(prediction_file, 'rb') as f:
                    st.download_button(
                        label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹",
                        data=f,
                        file_name=os.path.basename(prediction_file),
                        mime="text/csv"
                    )
        if st.session_state.prediction_history:
            st.markdown(
                '<div style="font-size:1.6rem; font-weight:700; color:#1565C0; margin-bottom:1rem;">Ø³Ø¬Ù„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª</div>',
                unsafe_allow_html=True
            )
            history_df = pd.DataFrame(st.session_state.prediction_history)
            st.dataframe(history_df, use_container_width=True)

if __name__ == "__main__":
    main()
